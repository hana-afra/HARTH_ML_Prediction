{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSn8VuU8aaIv"
      },
      "source": [
        "# **Support Vector Machine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sd75CYTlaZnK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn import svm, datasets\n",
        "import sklearn.model_selection as model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSOHVW6cazHr"
      },
      "source": [
        "### **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "prepares the dataset by handling missing values, scaling features, and removing outliers, followed by data splitting for further analysis or modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMpAnzaZ8FaR",
        "outputId": "edb5d580-254e-4f88-acb3-4ae8d79c8dc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing Values:\n",
            " timestamp    0\n",
            "back_x       0\n",
            "back_y       0\n",
            "back_z       0\n",
            "thigh_x      0\n",
            "thigh_y      0\n",
            "thigh_z      0\n",
            "label        0\n",
            "id           0\n",
            "dtype: int64\n",
            "\n",
            "Modified DataFrame:\n",
            "                timestamp    back_x    back_y    back_z   thigh_x   thigh_y  \\\n",
            "0 2019-01-12 00:00:00.000  0.330293  1.353248  1.749055 -7.181078 -0.822551   \n",
            "1 2019-01-12 00:00:00.010  0.939690  1.276724  1.341687  2.387553  0.684944   \n",
            "2 2019-01-12 00:00:00.020 -0.757338  0.863492  0.006493  0.893189 -0.255631   \n",
            "3 2019-01-12 00:00:00.030  0.625506  0.129082  0.315552 -1.531676 -2.501871   \n",
            "4 2019-01-12 00:00:00.040  1.403332 -0.166845  0.153423  0.075705  0.308988   \n",
            "\n",
            "    thigh_z  label  id  \n",
            "0  0.454455      6   0  \n",
            "1 -0.047014      6   0  \n",
            "2 -1.209252      6   0  \n",
            "3 -0.809751      6   0  \n",
            "4 -1.397501      6   0  \n",
            "\n",
            "Cleaned DataFrame:\n",
            "                timestamp    back_x    back_y    back_z   thigh_x   thigh_y  \\\n",
            "1 2019-01-12 00:00:00.010  0.939690  1.276724  1.341687  2.387553  0.684944   \n",
            "2 2019-01-12 00:00:00.020 -0.757338  0.863492  0.006493  0.893189 -0.255631   \n",
            "4 2019-01-12 00:00:00.040  1.403332 -0.166845  0.153423  0.075705  0.308988   \n",
            "5 2019-01-12 00:00:00.050  1.337504 -0.359878  0.398052 -0.569856  0.542315   \n",
            "6 2019-01-12 00:00:00.060 -0.800153  0.033537  0.619789  0.118332  0.344648   \n",
            "\n",
            "    thigh_z  label  id  \n",
            "1 -0.047014      6   0  \n",
            "2 -1.209252      6   0  \n",
            "4 -1.397501      6   0  \n",
            "5 -1.102051      6   0  \n",
            "6 -0.824694      6   0  \n",
            "\n",
            "Original number of rows: 6461328\n",
            "Number of rows after removing outliers: 5621385\n"
          ]
        }
      ],
      "source": [
        "# Read the combined dataset\n",
        "combined_df = pd.read_csv(\"combined_data_with_id_ordered.csv\")\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = combined_df.isnull().sum()\n",
        "print(\"Missing Values:\\n\", missing_values)\n",
        "\n",
        "\n",
        "# Convert 'timestamp' column to datetime format\n",
        "combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'])\n",
        "\n",
        "# Perform feature scaling\n",
        "columns_to_scale = ['back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']\n",
        "scaler = StandardScaler()\n",
        "combined_df[columns_to_scale] = scaler.fit_transform(combined_df[columns_to_scale])\n",
        "\n",
        "\n",
        "# Display the first few rows of the modified DataFrame\n",
        "print(\"\\nModified DataFrame:\")\n",
        "print(combined_df.head())\n",
        "\n",
        "# Function to detect and remove extreme outliers using the IQR method with a higher multiplier\n",
        "def remove_extreme_outliers_iqr(df, columns, multiplier=3.0):\n",
        "    for column in columns:\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - multiplier * IQR\n",
        "        upper_bound = Q3 + multiplier * IQR\n",
        "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "    return df\n",
        "\n",
        "# Apply the outlier removal function to the relevant columns with a higher multiplier\n",
        "columns_to_check = columns_to_scale  # The same columns that were scaled\n",
        "original_shape = combined_df.shape\n",
        "cleaned_df = remove_extreme_outliers_iqr(combined_df, columns_to_check, multiplier=3.0)\n",
        "cleaned_shape = cleaned_df.shape\n",
        "\n",
        "# Display the first few rows of the cleaned DataFrame\n",
        "print(\"\\nCleaned DataFrame:\")\n",
        "print(cleaned_df.head())\n",
        "\n",
        "# Display the number of rows before and after removing outliers\n",
        "print(\"\\nOriginal number of rows:\", original_shape[0])\n",
        "print(\"Number of rows after removing outliers:\", cleaned_shape[0])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAlZ6XY5hYSn"
      },
      "source": [
        "## **SVM with a sample**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Stratified sampling is performed to create a representative sample considering each participant's contribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4Todq8ohhgS9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of rows in the sampled DataFrame: 300000\n",
            "\n",
            "Number of instances in each class after sampling:\n",
            "label\n",
            "7      126294\n",
            "1       73017\n",
            "6       35175\n",
            "13      27872\n",
            "3       11995\n",
            "2       11090\n",
            "4        3967\n",
            "14       3488\n",
            "5        3270\n",
            "130      2828\n",
            "140       601\n",
            "8         403\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "num_participants = 22\n",
        "sample_size =300000\n",
        "\n",
        "# Calculate the sample size per participant\n",
        "sample_size_per_participant = sample_size // num_participants\n",
        "\n",
        "# Perform stratified sampling\n",
        "sampled_df = cleaned_df.groupby('id', group_keys=False).apply(lambda x: x.sample(min(len(x), sample_size_per_participant)))\n",
        "\n",
        "# If the total sampled rows are less than the desired sample size, sample the remaining randomly\n",
        "if len(sampled_df) < sample_size:\n",
        "    remaining_sample_size = sample_size - len(sampled_df)\n",
        "    remaining_sample = cleaned_df.drop(sampled_df.index).sample(remaining_sample_size)\n",
        "    sampled_df = pd.concat([sampled_df, remaining_sample])\n",
        "\n",
        "# Display the number of rows in the sampled DataFrame\n",
        "print(\"\\nNumber of rows in the sampled DataFrame:\", len(sampled_df))\n",
        "\n",
        "# Display the number of each class in the sampled DataFrame\n",
        "if 'label' in sampled_df.columns:\n",
        "    class_counts = sampled_df['label'].value_counts()\n",
        "    print(\"\\nNumber of instances in each class after sampling:\")\n",
        "    print(class_counts)\n",
        "else:\n",
        "    print(\"\\n'Class' column not found in the DataFrame.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "otJI8v0EicBo"
      },
      "outputs": [],
      "source": [
        "# Select features and target\n",
        "features = ['back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']\n",
        "X = sampled_df[features]\n",
        "y = sampled_df['label']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Two types of SVM models are trained: one with a One-vs-Rest (OvR) strategy and the other with a One-vs-One (OvO) strategy.\n",
        "   - SVM models are trained using the radial basis function (RBF) kernel with specific hyperparameters (gamma and C).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGtohMBpgBLd"
      },
      "source": [
        "### **ovr (One-vs-Rest)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "rbf = svm.SVC(kernel='rbf', gamma=2, C=20, decision_function_shape = \"ovr\").fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iWIVXix7AO6r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (RBF Kernel) on ovr:  86.42\n",
            "F1 on ovr: 0.8526058733503068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.85      0.83     21986\n",
            "           2       0.83      0.76      0.79      3273\n",
            "           3       0.41      0.17      0.24      3637\n",
            "           4       0.42      0.21      0.28      1213\n",
            "           5       0.29      0.11      0.16      1006\n",
            "           6       0.74      0.91      0.82     10396\n",
            "           7       0.99      0.99      0.99     37907\n",
            "           8       0.93      0.89      0.91       111\n",
            "          13       0.83      0.86      0.84      8368\n",
            "          14       0.65      0.50      0.57      1081\n",
            "         130       0.57      0.53      0.55       839\n",
            "         140       0.61      0.52      0.56       183\n",
            "\n",
            "    accuracy                           0.86     90000\n",
            "   macro avg       0.67      0.61      0.63     90000\n",
            "weighted avg       0.85      0.86      0.85     90000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rbf_pred = rbf.predict(X_test)\n",
        "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
        "\n",
        "print('Accuracy (RBF Kernel) on ovr: ', \"%.2f\" % (rbf_accuracy*100))\n",
        "print(\"F1 on ovr:\", f1_score(y_test, rbf_pred, average='weighted'))\n",
        "print(classification_report(y_test, rbf_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVM trained on undersampled data provides improved F1 scores for minority classes but at the cost of slightly reduced overall accuracy due to dataset size reduction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITADkcwDDYh0"
      },
      "source": [
        "### **ovo (One-vs-One)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lQItDgIfDhv7"
      },
      "outputs": [],
      "source": [
        "rbf = svm.SVC(kernel='rbf', gamma=2, C=20, decision_function_shape = \"ovo\").fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q086V3y9DoxM",
        "outputId": "2994ecdc-6fa6-4e40-8bc3-472d3dc2f2a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (RBF Kernel) on ovo:  86.42\n",
            "F1 on ovo : 0.8526058733503068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.85      0.83     21986\n",
            "           2       0.83      0.76      0.79      3273\n",
            "           3       0.41      0.17      0.24      3637\n",
            "           4       0.42      0.21      0.28      1213\n",
            "           5       0.29      0.11      0.16      1006\n",
            "           6       0.74      0.91      0.82     10396\n",
            "           7       0.99      0.99      0.99     37907\n",
            "           8       0.93      0.89      0.91       111\n",
            "          13       0.83      0.86      0.84      8368\n",
            "          14       0.65      0.50      0.57      1081\n",
            "         130       0.57      0.53      0.55       839\n",
            "         140       0.61      0.52      0.56       183\n",
            "\n",
            "    accuracy                           0.86     90000\n",
            "   macro avg       0.67      0.61      0.63     90000\n",
            "weighted avg       0.85      0.86      0.85     90000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rbf_pred = rbf.predict(X_test)\n",
        "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
        "\n",
        "print('Accuracy (RBF Kernel) on ovo: ', \"%.2f\" % (rbf_accuracy*100))\n",
        "print(\"F1 on ovo :\", f1_score(y_test, rbf_pred, average='weighted'))\n",
        "print(classification_report(y_test, rbf_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8qzaZWrGTeN"
      },
      "source": [
        "Both OvR and OvO SVM models achieve similar accuracy and F1 score, demonstrating robust performance across different multiclass strategies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnJJMFbODAR_"
      },
      "source": [
        "----------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHfXNmxAkeZ"
      },
      "source": [
        "## **SVM on an undersampled data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select features and target\n",
        "features = ['back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']\n",
        "X = cleaned_df[features]\n",
        "y = cleaned_df['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RandomUnderSampler is applied to balance the dataset by reducing the majority class instances.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SHaNq3p8SZ4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "1      7808\n",
            "2      7808\n",
            "3      7808\n",
            "4      7808\n",
            "5      7808\n",
            "6      7808\n",
            "7      7808\n",
            "8      7808\n",
            "13     7808\n",
            "14     7808\n",
            "130    7808\n",
            "140    7808\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Apply RandomUnderSampler to balance the dataset\n",
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "X_usampled, y_usampled = under_sampler.fit_resample(X, y)\n",
        "\n",
        "class_counts = y_usampled.value_counts()\n",
        "print(class_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zg0G6rsnuWl"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_usampled, y_usampled, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH0wPPmU86Vh"
      },
      "outputs": [],
      "source": [
        "rbf = svm.SVC(kernel='rbf', gamma=5, C=20, decision_function_shape = \"ovr\").fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLa8Pd1C9UiK",
        "outputId": "f212e43e-fd6a-4896-9faf-4d8fa1004b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with undersampling (RBF Kernel):  68.10\n",
            "F1 Undersampling: 0.6785805810812949\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.45      0.41      0.43      2297\n",
            "           2       0.56      0.80      0.66      2325\n",
            "           3       0.50      0.48      0.49      2319\n",
            "           4       0.54      0.51      0.53      2303\n",
            "           5       0.52      0.45      0.48      2456\n",
            "           6       0.72      0.79      0.75      2388\n",
            "           7       0.97      0.98      0.98      2349\n",
            "           8       0.98      0.96      0.97      2347\n",
            "          13       0.65      0.61      0.63      2364\n",
            "          14       0.73      0.65      0.69      2391\n",
            "         130       0.76      0.72      0.74      2300\n",
            "         140       0.79      0.80      0.79      2270\n",
            "\n",
            "    accuracy                           0.68     28109\n",
            "   macro avg       0.68      0.68      0.68     28109\n",
            "weighted avg       0.68      0.68      0.68     28109\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rbf_pred = rbf.predict(X_test)\n",
        "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
        "\n",
        "print('Accuracy with undersampling (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
        "print(\"F1 Undersampling:\", f1_score(y_test, rbf_pred, average='weighted'))\n",
        "print(classification_report(y_test, rbf_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SVM trained on undersampled data shows improved F1 score for minority classes compared to the models trained on the original or sampled datasets. However, there's a slight decrease in overall accuracy due to the reduction in the dataset size.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
